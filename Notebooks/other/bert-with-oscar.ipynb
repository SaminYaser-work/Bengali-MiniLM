{"cells":[{"cell_type":"code","execution_count":1,"metadata":{"execution":{"iopub.execute_input":"2022-07-06T05:02:04.342855Z","iopub.status.busy":"2022-07-06T05:02:04.341950Z","iopub.status.idle":"2022-07-06T05:02:04.351273Z","shell.execute_reply":"2022-07-06T05:02:04.350389Z","shell.execute_reply.started":"2022-07-06T05:02:04.342810Z"},"trusted":true},"outputs":[],"source":["from transformers import pipeline, AutoTokenizer, BertConfig, AutoModelForMaskedLM, BertForMaskedLM, AdamW, DistilBertTokenizer, DistilBertForMaskedLM, DistilBertConfig\n","import torch\n","from tqdm import tqdm\n","from tokenizers import Tokenizer\n","from tokenizers.models import BPE\n","from tokenizers.trainers import BpeTrainer\n","from tokenizers.pre_tokenizers import Whitespace\n","from transformers import Trainer, TrainingArguments\n","from transformers import DataCollatorForLanguageModeling\n","from datasets import load_dataset, Dataset\n","import pandas as pd"]},{"cell_type":"code","execution_count":2,"metadata":{},"outputs":[],"source":["path_to_csv = '../Datasets/oscar/test.csv'\n","path_to_model = '../Models/distilbert/'"]},{"cell_type":"code","execution_count":2,"metadata":{},"outputs":[{"ename":"AssertionError","evalue":"Torch not compiled with CUDA enabled","output_type":"error","traceback":["\u001b[1;31m---------------------------------------------------------------------------\u001b[0m","\u001b[1;31mAssertionError\u001b[0m                            Traceback (most recent call last)","\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_3636/811727375.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mtorch\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[1;31m# torch.cuda.is_available()\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 3\u001b[1;33m \u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mzeros\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcuda\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m","\u001b[1;32mc:\\ProgramData\\Anaconda3\\lib\\site-packages\\torch\\cuda\\__init__.py\u001b[0m in \u001b[0;36m_lazy_init\u001b[1;34m()\u001b[0m\n\u001b[0;32m    208\u001b[0m                 \"multiprocessing, you must use the 'spawn' start method\")\n\u001b[0;32m    209\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0mhasattr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_C\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'_cuda_getDeviceCount'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 210\u001b[1;33m             \u001b[1;32mraise\u001b[0m \u001b[0mAssertionError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"Torch not compiled with CUDA enabled\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    211\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0m_cudart\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    212\u001b[0m             raise AssertionError(\n","\u001b[1;31mAssertionError\u001b[0m: Torch not compiled with CUDA enabled"]}],"source":["import torch\n","# torch.cuda.is_available()\n","torch.zeros(1).cuda()"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2022-07-05T16:24:03.052865Z","iopub.status.busy":"2022-07-05T16:24:03.052208Z","iopub.status.idle":"2022-07-05T16:24:03.059278Z","shell.execute_reply":"2022-07-05T16:24:03.058008Z","shell.execute_reply.started":"2022-07-05T16:24:03.052826Z"},"trusted":true},"outputs":[],"source":["# # !pip install tokenizers\n","# from tokenizers import BertWordPieceTokenizer\n","\n","# path = ['../input/oscar-bn-1-cleaned/test.txt']\n","\n","# # initialize\n","# tokenizer = BertWordPieceTokenizer(\n","#     clean_text=True,\n","#     handle_chinese_chars=False,\n","#     strip_accents=False,\n","#     lowercase=False\n","# )\n","# # and train\n","# tokenizer.train(files=path, vocab_size=50_000, min_frequency=2,\n","#                 limit_alphabet=1000, wordpieces_prefix='##',\n","#                 special_tokens=[\n","#                     '[PAD]', '[UNK]', '[CLS]', '[SEP]', '[MASK]'])\n","\n"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2022-07-05T16:24:03.06444Z","iopub.status.busy":"2022-07-05T16:24:03.063632Z","iopub.status.idle":"2022-07-05T16:30:42.471668Z","shell.execute_reply":"2022-07-05T16:30:42.470556Z","shell.execute_reply.started":"2022-07-05T16:24:03.064372Z"},"trusted":true},"outputs":[],"source":["# tokenizer = Tokenizer(BPE(unk_token=\"[UNK]\"))\n","# trainer = BpeTrainer(special_tokens=[\"[UNK]\", \"[CLS]\", \"[SEP]\", \"[PAD]\", \"[MASK]\"])\n","\n","# tokenizer.pre_tokenizer = Whitespace()\n","# files = ['../input/oscar-bn-1-cleaned/test.txt']\n","# tokenizer.train(files, trainer)"]},{"cell_type":"code","execution_count":3,"metadata":{"execution":{"iopub.execute_input":"2022-07-06T05:02:09.318896Z","iopub.status.busy":"2022-07-06T05:02:09.318444Z","iopub.status.idle":"2022-07-06T05:02:10.056996Z","shell.execute_reply":"2022-07-06T05:02:10.056063Z","shell.execute_reply.started":"2022-07-06T05:02:09.318856Z"},"trusted":true},"outputs":[],"source":["tokenizer = AutoTokenizer.from_pretrained(\"csebuetnlp/banglabert_generator\", use_fast=False)"]},{"cell_type":"code","execution_count":5,"metadata":{"execution":{"iopub.execute_input":"2022-07-06T05:02:13.411770Z","iopub.status.busy":"2022-07-06T05:02:13.410962Z","iopub.status.idle":"2022-07-06T05:02:13.420479Z","shell.execute_reply":"2022-07-06T05:02:13.419367Z","shell.execute_reply.started":"2022-07-06T05:02:13.411717Z"},"trusted":true},"outputs":[],"source":["tokenizer([\"আমি বাংলায় গান গাই।\" , \"আমি বাংলায় গান গাই।\", \"আমি বাংলায় গান গাই।\"])"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2022-07-05T16:30:42.48953Z","iopub.status.busy":"2022-07-05T16:30:42.488593Z","iopub.status.idle":"2022-07-05T16:30:42.505865Z","shell.execute_reply":"2022-07-05T16:30:42.5047Z","shell.execute_reply.started":"2022-07-05T16:30:42.489493Z"},"trusted":true},"outputs":[],"source":["# tokenizer.save_model('/kaggle/working/bert-bangla', 'bert-bangla')"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2022-07-05T16:32:28.467162Z","iopub.status.busy":"2022-07-05T16:32:28.466764Z","iopub.status.idle":"2022-07-05T16:32:28.498204Z","shell.execute_reply":"2022-07-05T16:32:28.496887Z","shell.execute_reply.started":"2022-07-05T16:32:28.467132Z"},"trusted":true},"outputs":[],"source":["# tokenizer.save(\"/kaggle/working/vocab.json\")"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["# tokenizer = Tokenizer.from_file(\"data/tokenizer-wiki.json\")"]},{"cell_type":"code","execution_count":34,"metadata":{"execution":{"iopub.execute_input":"2022-07-06T04:39:48.984682Z","iopub.status.busy":"2022-07-06T04:39:48.984007Z","iopub.status.idle":"2022-07-06T04:39:49.178994Z","shell.execute_reply":"2022-07-06T04:39:49.178026Z","shell.execute_reply.started":"2022-07-06T04:39:48.984641Z"},"trusted":true},"outputs":[],"source":["# tokenizer = DistilBertTokenizer.from_pretrained('../input/dbtkn1/distilbert-tokenizer.json')"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2022-07-05T16:33:27.626581Z","iopub.status.busy":"2022-07-05T16:33:27.626127Z","iopub.status.idle":"2022-07-05T16:33:27.631983Z","shell.execute_reply":"2022-07-05T16:33:27.631067Z","shell.execute_reply.started":"2022-07-05T16:33:27.626536Z"},"trusted":true},"outputs":[],"source":["# tokens = tokenizer.encode('আমি বাংলায় গান গাই।')\n","# tokenizer.convert_ids_to_tokens(tokens.input_ids)"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2022-07-05T16:33:53.265335Z","iopub.status.busy":"2022-07-05T16:33:53.264983Z","iopub.status.idle":"2022-07-05T16:33:53.271914Z","shell.execute_reply":"2022-07-05T16:33:53.270873Z","shell.execute_reply.started":"2022-07-05T16:33:53.265302Z"},"trusted":true},"outputs":[],"source":["# tokens.tokens"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.status.busy":"2022-07-05T16:30:43.092416Z","iopub.status.idle":"2022-07-05T16:30:43.093293Z","shell.execute_reply":"2022-07-05T16:30:43.093082Z","shell.execute_reply.started":"2022-07-05T16:30:43.093058Z"},"trusted":true},"outputs":[],"source":["# encoding = tokenizer.encode_plus(text, add_special_tokens = True, truncation = True, padding = \"max_length\", return_attention_mask = True, return_tensors = \"pt\")"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.status.busy":"2022-07-05T16:30:43.094916Z","iopub.status.idle":"2022-07-05T16:30:43.095383Z","shell.execute_reply":"2022-07-05T16:30:43.095167Z","shell.execute_reply.started":"2022-07-05T16:30:43.095146Z"},"trusted":true},"outputs":[],"source":["# with open('/kaggle/working/tkn-vocab.txt', 'r') as fp:\n","#     vocab = fp.read().split('\\n')"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.status.busy":"2022-07-05T16:30:43.09717Z","iopub.status.idle":"2022-07-05T16:30:43.09764Z","shell.execute_reply":"2022-07-05T16:30:43.097407Z","shell.execute_reply.started":"2022-07-05T16:30:43.097386Z"},"trusted":true},"outputs":[],"source":["# vocab[478], vocab[1231], vocab[136], vocab[1862], vocab[5020] "]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.status.busy":"2022-07-05T16:30:43.099402Z","iopub.status.idle":"2022-07-05T16:30:43.099861Z","shell.execute_reply":"2022-07-05T16:30:43.099649Z","shell.execute_reply.started":"2022-07-05T16:30:43.099628Z"},"trusted":true},"outputs":[],"source":["# with open(path_to_csv, 'r', encoding='utf-8') as fp:\n","#     lines = fp.read().split('\\n')"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.status.busy":"2022-07-05T16:30:43.102694Z","iopub.status.idle":"2022-07-05T16:30:43.103515Z","shell.execute_reply":"2022-07-05T16:30:43.103297Z","shell.execute_reply.started":"2022-07-05T16:30:43.103273Z"},"trusted":true},"outputs":[],"source":["# lines[0]"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.status.busy":"2022-07-05T16:30:43.104589Z","iopub.status.idle":"2022-07-05T16:30:43.105614Z","shell.execute_reply":"2022-07-05T16:30:43.105381Z","shell.execute_reply.started":"2022-07-05T16:30:43.105356Z"},"trusted":true},"outputs":[],"source":["# len(lines)"]},{"cell_type":"code","execution_count":11,"metadata":{"execution":{"iopub.execute_input":"2022-07-06T05:07:10.801260Z","iopub.status.busy":"2022-07-06T05:07:10.800883Z","iopub.status.idle":"2022-07-06T05:07:24.703035Z","shell.execute_reply":"2022-07-06T05:07:24.702062Z","shell.execute_reply.started":"2022-07-06T05:07:10.801229Z"},"trusted":true},"outputs":[],"source":["# df = pd.read_csv(path_to_csv)"]},{"cell_type":"code","execution_count":8,"metadata":{"execution":{"iopub.execute_input":"2022-07-06T05:08:29.509570Z","iopub.status.busy":"2022-07-06T05:08:29.509065Z","iopub.status.idle":"2022-07-06T05:08:30.109753Z","shell.execute_reply":"2022-07-06T05:08:30.108644Z","shell.execute_reply.started":"2022-07-06T05:08:29.509527Z"},"trusted":true},"outputs":[],"source":["# df = df[df['text'].notna()]"]},{"cell_type":"code","execution_count":12,"metadata":{},"outputs":[{"data":{"text/plain":["text    0\n","dtype: int64"]},"execution_count":12,"metadata":{},"output_type":"execute_result"}],"source":["# df.isna().sum()"]},{"cell_type":"code","execution_count":10,"metadata":{},"outputs":[],"source":["# df.to_csv(path_to_csv, index=False)"]},{"cell_type":"code","execution_count":4,"metadata":{"execution":{"iopub.execute_input":"2022-07-06T04:33:47.443457Z","iopub.status.busy":"2022-07-06T04:33:47.442797Z","iopub.status.idle":"2022-07-06T04:33:47.860720Z","shell.execute_reply":"2022-07-06T04:33:47.859800Z","shell.execute_reply.started":"2022-07-06T04:33:47.443408Z"},"trusted":true},"outputs":[{"name":"stderr","output_type":"stream","text":["Using custom data configuration default-200ed0a731ad30b9\n"]},{"name":"stdout","output_type":"stream","text":["Downloading and preparing dataset csv/default to C:\\Users\\samin\\.cache\\huggingface\\datasets\\csv\\default-200ed0a731ad30b9\\0.0.0\\51cce309a08df9c4d82ffd9363bbe090bf173197fc01a71b034e8594995a1a58...\n"]},{"name":"stderr","output_type":"stream","text":["Downloading data files: 100%|██████████| 1/1 [00:00<00:00, 1030.29it/s]\n","Extracting data files: 100%|██████████| 1/1 [00:00<00:00, 250.08it/s]\n","                                  \r"]},{"name":"stdout","output_type":"stream","text":["Dataset csv downloaded and prepared to C:\\Users\\samin\\.cache\\huggingface\\datasets\\csv\\default-200ed0a731ad30b9\\0.0.0\\51cce309a08df9c4d82ffd9363bbe090bf173197fc01a71b034e8594995a1a58. Subsequent calls will reuse this data.\n"]},{"name":"stderr","output_type":"stream","text":["100%|██████████| 1/1 [00:00<00:00,  7.19it/s]\n"]}],"source":["dataset = load_dataset('csv', data_files=path_to_csv)"]},{"cell_type":"code","execution_count":26,"metadata":{"execution":{"iopub.execute_input":"2022-07-06T05:08:45.174470Z","iopub.status.busy":"2022-07-06T05:08:45.174026Z","iopub.status.idle":"2022-07-06T05:08:49.472027Z","shell.execute_reply":"2022-07-06T05:08:49.471059Z","shell.execute_reply.started":"2022-07-06T05:08:45.174432Z"},"trusted":true},"outputs":[],"source":["# dataset = Dataset.from_pandas(df)"]},{"cell_type":"code","execution_count":5,"metadata":{"execution":{"iopub.execute_input":"2022-07-06T05:08:51.645935Z","iopub.status.busy":"2022-07-06T05:08:51.645537Z","iopub.status.idle":"2022-07-06T05:08:51.652275Z","shell.execute_reply":"2022-07-06T05:08:51.651161Z","shell.execute_reply.started":"2022-07-06T05:08:51.645906Z"},"trusted":true},"outputs":[{"data":{"text/plain":["DatasetDict({\n","    train: Dataset({\n","        features: ['text'],\n","        num_rows: 1266786\n","    })\n","})"]},"execution_count":5,"metadata":{},"output_type":"execute_result"}],"source":["dataset"]},{"cell_type":"code","execution_count":23,"metadata":{"execution":{"iopub.execute_input":"2022-07-06T04:35:09.436593Z","iopub.status.busy":"2022-07-06T04:35:09.435895Z","iopub.status.idle":"2022-07-06T04:35:12.827914Z","shell.execute_reply":"2022-07-06T04:35:12.826928Z","shell.execute_reply.started":"2022-07-06T04:35:09.436556Z"},"trusted":true},"outputs":[],"source":["# test = dataset['train'].to_pandas()"]},{"cell_type":"code","execution_count":8,"metadata":{"execution":{"iopub.execute_input":"2022-07-06T05:09:03.208998Z","iopub.status.busy":"2022-07-06T05:09:03.208626Z","iopub.status.idle":"2022-07-06T05:09:07.860233Z","shell.execute_reply":"2022-07-06T05:09:07.859159Z","shell.execute_reply.started":"2022-07-06T05:09:03.208968Z"},"trusted":true},"outputs":[{"ename":"KeyError","evalue":"'text'","output_type":"error","traceback":["\u001b[1;31m---------------------------------------------------------------------------\u001b[0m","\u001b[1;31mKeyError\u001b[0m                                  Traceback (most recent call last)","\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_2180/4192472845.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mdataset\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'text'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m","\u001b[1;32mc:\\ProgramData\\Anaconda3\\lib\\site-packages\\datasets\\dataset_dict.py\u001b[0m in \u001b[0;36m__getitem__\u001b[1;34m(self, k)\u001b[0m\n\u001b[0;32m     48\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m__getitem__\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mk\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m->\u001b[0m \u001b[0mDataset\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     49\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mk\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mstr\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mNamedSplit\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mor\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 50\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0msuper\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__getitem__\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mk\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     51\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     52\u001b[0m             available_suggested_splits = [\n","\u001b[1;31mKeyError\u001b[0m: 'text'"]}],"source":["# dataset"]},{"cell_type":"code","execution_count":25,"metadata":{"execution":{"iopub.execute_input":"2022-07-06T05:12:37.994953Z","iopub.status.busy":"2022-07-06T05:12:37.994604Z","iopub.status.idle":"2022-07-06T05:12:38.000016Z","shell.execute_reply":"2022-07-06T05:12:37.999053Z","shell.execute_reply.started":"2022-07-06T05:12:37.994925Z"},"trusted":true},"outputs":[],"source":["def tokenize_text(example):\n","#     print(example['text'][:1])\n","    return tokenizer(example['text'], truncation=True, padding='max_length', max_length=512)"]},{"cell_type":"code","execution_count":27,"metadata":{"execution":{"iopub.execute_input":"2022-07-06T04:58:48.703294Z","iopub.status.busy":"2022-07-06T04:58:48.702319Z","iopub.status.idle":"2022-07-06T04:58:52.864694Z","shell.execute_reply":"2022-07-06T04:58:52.863279Z","shell.execute_reply.started":"2022-07-06T04:58:48.703254Z"},"trusted":true},"outputs":[{"data":{"text/plain":["{'input_ids': [[2, 7064, 16723, 900, 15257, 1148, 1, 9823, 1237, 11274, 8171, 3391, 4523, 416, 219, 13020, 15750, 8478, 837, 18391, 1119, 1, 2990, 15293, 817, 1810, 1277, 7252, 2463, 1790, 1119, 7577, 10591, 1650, 424, 1599, 431, 925, 2170, 1818, 7706, 8478, 837, 18391, 1172, 1165, 1217, 1954, 2524, 13548, 1615, 17376, 17376, 17376, 17376, 269, 17376, 8607, 837, 1065, 788, 7706, 2415, 1858, 1, 1910, 5972, 4807, 7678, 1349, 830, 3990, 1248, 1, 23820, 1, 1217, 11321, 2635, 10965, 411, 1, 1054, 889, 9409, 792, 1, 1092, 3]], 'token_type_ids': [[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]], 'attention_mask': [[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]]}"]},"execution_count":27,"metadata":{},"output_type":"execute_result"}],"source":["tokenizer(dataset['train']['text'][:1])"]},{"cell_type":"code","execution_count":28,"metadata":{"execution":{"iopub.execute_input":"2022-07-06T05:12:39.857126Z","iopub.status.busy":"2022-07-06T05:12:39.856753Z"},"trusted":true},"outputs":[{"name":"stderr","output_type":"stream","text":["100%|██████████| 1267/1267 [29:26<00:00,  1.39s/ba]\n"]}],"source":["ds =  dataset.map(tokenize_text, batched=True)"]},{"cell_type":"code","execution_count":29,"metadata":{},"outputs":[],"source":["batch = ds"]},{"cell_type":"code","execution_count":30,"metadata":{},"outputs":[{"data":{"text/plain":["DatasetDict({\n","    train: Dataset({\n","        features: ['text', 'input_ids', 'token_type_ids', 'attention_mask'],\n","        num_rows: 1266786\n","    })\n","})"]},"execution_count":30,"metadata":{},"output_type":"execute_result"}],"source":["batch"]},{"cell_type":"code","execution_count":31,"metadata":{"execution":{"iopub.execute_input":"2022-07-06T01:32:44.524973Z","iopub.status.busy":"2022-07-06T01:32:44.524610Z","iopub.status.idle":"2022-07-06T01:32:49.214115Z","shell.execute_reply":"2022-07-06T01:32:49.213130Z","shell.execute_reply.started":"2022-07-06T01:32:44.524941Z"},"trusted":true},"outputs":[],"source":["# lines = []\n","\n","# with open('../input/oscar-bn-1-cleaned/test.txt', 'r', encoding='utf-8') as fp:\n","#     lines = fp.read().split('\\n')"]},{"cell_type":"code","execution_count":32,"metadata":{"trusted":true},"outputs":[],"source":["# batch = tokenizer(lines, max_length=512, padding=True, truncation=True, return_tensors=\"pt\")"]},{"cell_type":"code","execution_count":33,"metadata":{"execution":{"iopub.status.busy":"2022-07-05T16:30:43.109116Z","iopub.status.idle":"2022-07-05T16:30:43.110142Z","shell.execute_reply":"2022-07-05T16:30:43.109889Z","shell.execute_reply.started":"2022-07-05T16:30:43.109866Z"},"trusted":true},"outputs":[],"source":["# len(batch)"]},{"cell_type":"code","execution_count":34,"metadata":{"execution":{"iopub.status.busy":"2022-07-05T16:30:43.111429Z","iopub.status.idle":"2022-07-05T16:30:43.112234Z","shell.execute_reply":"2022-07-05T16:30:43.112009Z","shell.execute_reply.started":"2022-07-05T16:30:43.111986Z"},"trusted":true},"outputs":[],"source":["# print(batch[\"input_ids\"])"]},{"cell_type":"code","execution_count":35,"metadata":{"execution":{"iopub.status.busy":"2022-07-05T16:30:43.113529Z","iopub.status.idle":"2022-07-05T16:30:43.114483Z","shell.execute_reply":"2022-07-05T16:30:43.114251Z","shell.execute_reply.started":"2022-07-05T16:30:43.114226Z"},"trusted":true},"outputs":[],"source":["labels = torch.tensor([x for x in batch['train']['input_ids']])\n","mask = torch.tensor([x for x in batch['train']['attention_mask']])"]},{"cell_type":"code","execution_count":36,"metadata":{"execution":{"iopub.status.busy":"2022-07-05T16:30:43.115862Z","iopub.status.idle":"2022-07-05T16:30:43.116756Z","shell.execute_reply":"2022-07-05T16:30:43.116504Z","shell.execute_reply.started":"2022-07-05T16:30:43.11648Z"},"trusted":true},"outputs":[],"source":["# make copy of labels tensor, this will be input_ids\n","input_ids = labels.detach().clone()\n","# create random array of floats with equal dims to input_ids\n","rand = torch.rand(input_ids.shape)\n","# mask random 15% where token is not 0 [PAD], 1 [CLS], or 2 [SEP]\n","# mask_arr = (rand < .15) * (input_ids != 0) * (input_ids != 1) * (input_ids != 2)\n","mask_arr = (rand < .15) * (input_ids > 2) \n","# loop through each row in input_ids tensor (cannot do in parallel)\n","for i in range(input_ids.shape[0]):\n","    # get indices of mask positions from mask array\n","    selection = torch.flatten(mask_arr[i].nonzero()).tolist()\n","    # mask input_ids\n","    input_ids[i, selection] = 4  # our custom [MASK] token == 3"]},{"cell_type":"code","execution_count":37,"metadata":{"execution":{"iopub.status.busy":"2022-07-05T16:30:43.118282Z","iopub.status.idle":"2022-07-05T16:30:43.119139Z","shell.execute_reply":"2022-07-05T16:30:43.118843Z","shell.execute_reply.started":"2022-07-05T16:30:43.118819Z"},"trusted":true},"outputs":[],"source":["encodings = {'input_ids': input_ids, 'attention_mask': mask, 'labels': labels}"]},{"cell_type":"code","execution_count":38,"metadata":{"execution":{"iopub.status.busy":"2022-07-05T16:30:43.120434Z","iopub.status.idle":"2022-07-05T16:30:43.121244Z","shell.execute_reply":"2022-07-05T16:30:43.121016Z","shell.execute_reply.started":"2022-07-05T16:30:43.120993Z"},"trusted":true},"outputs":[],"source":["class Dataset(torch.utils.data.Dataset):\n","    def __init__(self, encodings):\n","        # store encodings internally\n","        self.encodings = encodings\n","\n","    def __len__(self):\n","        # return the number of samples\n","        return self.encodings['input_ids'].shape[0]\n","\n","    def __getitem__(self, i):\n","        # return dictionary of input_ids, attention_mask, and labels for index i\n","        return {key: tensor[i] for key, tensor in self.encodings.items()}"]},{"cell_type":"code","execution_count":39,"metadata":{"execution":{"iopub.status.busy":"2022-07-05T16:30:43.12254Z","iopub.status.idle":"2022-07-05T16:30:43.123449Z","shell.execute_reply":"2022-07-05T16:30:43.123233Z","shell.execute_reply.started":"2022-07-05T16:30:43.123211Z"},"trusted":true},"outputs":[],"source":["dataset = Dataset(encodings)"]},{"cell_type":"code","execution_count":40,"metadata":{"execution":{"iopub.status.busy":"2022-07-05T16:30:43.124753Z","iopub.status.idle":"2022-07-05T16:30:43.125723Z","shell.execute_reply":"2022-07-05T16:30:43.125488Z","shell.execute_reply.started":"2022-07-05T16:30:43.125463Z"},"trusted":true},"outputs":[],"source":["loader = torch.utils.data.DataLoader(dataset, batch_size=16, shuffle=True) "]},{"cell_type":"code","execution_count":41,"metadata":{},"outputs":[],"source":["# tokenizer.pad_token = tokenizer.eos_token\n","# data_collator = DataCollatorForLanguageModeling(tokenizer=tokenizer, mlm_probability=0.15)"]},{"cell_type":"code","execution_count":49,"metadata":{"execution":{"iopub.status.busy":"2022-07-05T16:30:43.127892Z","iopub.status.idle":"2022-07-05T16:30:43.128842Z","shell.execute_reply":"2022-07-05T16:30:43.12861Z","shell.execute_reply.started":"2022-07-05T16:30:43.128585Z"},"trusted":true},"outputs":[],"source":["# config = RobertaConfig(\n","#     vocab_size=50_522,  # we align this to the tokenizer vocab_size\n","#     max_position_embeddings=514,\n","#     hidden_size=768,\n","#     num_attention_heads=12,\n","#     num_hidden_layers=6,\n","#     type_vocab_size=1\n","#     )\n","\n","config = DistilBertConfig(max_position_embeddings=512)"]},{"cell_type":"code","execution_count":50,"metadata":{"execution":{"iopub.status.busy":"2022-07-05T16:30:43.130037Z","iopub.status.idle":"2022-07-05T16:30:43.130986Z","shell.execute_reply":"2022-07-05T16:30:43.130733Z","shell.execute_reply.started":"2022-07-05T16:30:43.130706Z"},"trusted":true},"outputs":[],"source":["model = DistilBertForMaskedLM(config) "]},{"cell_type":"code","execution_count":51,"metadata":{"execution":{"iopub.status.busy":"2022-07-05T16:30:43.132181Z","iopub.status.idle":"2022-07-05T16:30:43.133075Z","shell.execute_reply":"2022-07-05T16:30:43.132831Z","shell.execute_reply.started":"2022-07-05T16:30:43.132807Z"},"trusted":true},"outputs":[{"data":{"text/plain":["DistilBertForMaskedLM(\n","  (activation): GELUActivation()\n","  (distilbert): DistilBertModel(\n","    (embeddings): Embeddings(\n","      (word_embeddings): Embedding(30522, 768, padding_idx=0)\n","      (position_embeddings): Embedding(512, 768)\n","      (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","      (dropout): Dropout(p=0.1, inplace=False)\n","    )\n","    (transformer): Transformer(\n","      (layer): ModuleList(\n","        (0): TransformerBlock(\n","          (attention): MultiHeadSelfAttention(\n","            (dropout): Dropout(p=0.1, inplace=False)\n","            (q_lin): Linear(in_features=768, out_features=768, bias=True)\n","            (k_lin): Linear(in_features=768, out_features=768, bias=True)\n","            (v_lin): Linear(in_features=768, out_features=768, bias=True)\n","            (out_lin): Linear(in_features=768, out_features=768, bias=True)\n","          )\n","          (sa_layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","          (ffn): FFN(\n","            (dropout): Dropout(p=0.1, inplace=False)\n","            (lin1): Linear(in_features=768, out_features=3072, bias=True)\n","            (lin2): Linear(in_features=3072, out_features=768, bias=True)\n","            (activation): GELUActivation()\n","          )\n","          (output_layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","        )\n","        (1): TransformerBlock(\n","          (attention): MultiHeadSelfAttention(\n","            (dropout): Dropout(p=0.1, inplace=False)\n","            (q_lin): Linear(in_features=768, out_features=768, bias=True)\n","            (k_lin): Linear(in_features=768, out_features=768, bias=True)\n","            (v_lin): Linear(in_features=768, out_features=768, bias=True)\n","            (out_lin): Linear(in_features=768, out_features=768, bias=True)\n","          )\n","          (sa_layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","          (ffn): FFN(\n","            (dropout): Dropout(p=0.1, inplace=False)\n","            (lin1): Linear(in_features=768, out_features=3072, bias=True)\n","            (lin2): Linear(in_features=3072, out_features=768, bias=True)\n","            (activation): GELUActivation()\n","          )\n","          (output_layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","        )\n","        (2): TransformerBlock(\n","          (attention): MultiHeadSelfAttention(\n","            (dropout): Dropout(p=0.1, inplace=False)\n","            (q_lin): Linear(in_features=768, out_features=768, bias=True)\n","            (k_lin): Linear(in_features=768, out_features=768, bias=True)\n","            (v_lin): Linear(in_features=768, out_features=768, bias=True)\n","            (out_lin): Linear(in_features=768, out_features=768, bias=True)\n","          )\n","          (sa_layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","          (ffn): FFN(\n","            (dropout): Dropout(p=0.1, inplace=False)\n","            (lin1): Linear(in_features=768, out_features=3072, bias=True)\n","            (lin2): Linear(in_features=3072, out_features=768, bias=True)\n","            (activation): GELUActivation()\n","          )\n","          (output_layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","        )\n","        (3): TransformerBlock(\n","          (attention): MultiHeadSelfAttention(\n","            (dropout): Dropout(p=0.1, inplace=False)\n","            (q_lin): Linear(in_features=768, out_features=768, bias=True)\n","            (k_lin): Linear(in_features=768, out_features=768, bias=True)\n","            (v_lin): Linear(in_features=768, out_features=768, bias=True)\n","            (out_lin): Linear(in_features=768, out_features=768, bias=True)\n","          )\n","          (sa_layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","          (ffn): FFN(\n","            (dropout): Dropout(p=0.1, inplace=False)\n","            (lin1): Linear(in_features=768, out_features=3072, bias=True)\n","            (lin2): Linear(in_features=3072, out_features=768, bias=True)\n","            (activation): GELUActivation()\n","          )\n","          (output_layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","        )\n","        (4): TransformerBlock(\n","          (attention): MultiHeadSelfAttention(\n","            (dropout): Dropout(p=0.1, inplace=False)\n","            (q_lin): Linear(in_features=768, out_features=768, bias=True)\n","            (k_lin): Linear(in_features=768, out_features=768, bias=True)\n","            (v_lin): Linear(in_features=768, out_features=768, bias=True)\n","            (out_lin): Linear(in_features=768, out_features=768, bias=True)\n","          )\n","          (sa_layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","          (ffn): FFN(\n","            (dropout): Dropout(p=0.1, inplace=False)\n","            (lin1): Linear(in_features=768, out_features=3072, bias=True)\n","            (lin2): Linear(in_features=3072, out_features=768, bias=True)\n","            (activation): GELUActivation()\n","          )\n","          (output_layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","        )\n","        (5): TransformerBlock(\n","          (attention): MultiHeadSelfAttention(\n","            (dropout): Dropout(p=0.1, inplace=False)\n","            (q_lin): Linear(in_features=768, out_features=768, bias=True)\n","            (k_lin): Linear(in_features=768, out_features=768, bias=True)\n","            (v_lin): Linear(in_features=768, out_features=768, bias=True)\n","            (out_lin): Linear(in_features=768, out_features=768, bias=True)\n","          )\n","          (sa_layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","          (ffn): FFN(\n","            (dropout): Dropout(p=0.1, inplace=False)\n","            (lin1): Linear(in_features=768, out_features=3072, bias=True)\n","            (lin2): Linear(in_features=3072, out_features=768, bias=True)\n","            (activation): GELUActivation()\n","          )\n","          (output_layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","        )\n","      )\n","    )\n","  )\n","  (vocab_transform): Linear(in_features=768, out_features=768, bias=True)\n","  (vocab_layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","  (vocab_projector): Linear(in_features=768, out_features=30522, bias=True)\n","  (mlm_loss_fct): CrossEntropyLoss()\n",")"]},"execution_count":51,"metadata":{},"output_type":"execute_result"}],"source":["device = torch.device('cuda') if torch.cuda.is_available() else torch.device('cpu')\n","# and move our model over to the selected device\n","model.to(device)"]},{"cell_type":"code","execution_count":52,"metadata":{"execution":{"iopub.status.busy":"2022-07-05T16:30:43.134296Z","iopub.status.idle":"2022-07-05T16:30:43.135229Z","shell.execute_reply":"2022-07-05T16:30:43.134995Z","shell.execute_reply.started":"2022-07-05T16:30:43.134971Z"},"trusted":true},"outputs":[{"name":"stderr","output_type":"stream","text":["c:\\ProgramData\\Anaconda3\\lib\\site-packages\\transformers\\optimization.py:306: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n","  warnings.warn(\n"]}],"source":["# activate training mode\n","model.train()\n","# initialize optimizer\n","optim = AdamW(model.parameters(), lr=1e-4)"]},{"cell_type":"code","execution_count":53,"metadata":{},"outputs":[],"source":["# training_args = TrainingArguments(\n","#     output_dir=\"/kaggle/working/\",\n","#     evaluation_strategy=\"epoch\",\n","#     learning_rate=2e-5,\n","#     num_train_epochs=2,\n","#     weight_decay=0.01,\n","#     fp16=True\n","# )\n","\n","# trainer = Trainer(\n","#     model=model,\n","#     args=training_args,\n","#     train_dataset=batch,\n","#     data_collator=data_collator,\n","# )"]},{"cell_type":"code","execution_count":54,"metadata":{},"outputs":[],"source":["# trainer.train()"]},{"cell_type":"code","execution_count":55,"metadata":{"execution":{"iopub.status.busy":"2022-07-05T16:30:43.136429Z","iopub.status.idle":"2022-07-05T16:30:43.137291Z","shell.execute_reply":"2022-07-05T16:30:43.13714Z","shell.execute_reply.started":"2022-07-05T16:30:43.137118Z"},"trusted":true},"outputs":[{"name":"stderr","output_type":"stream","text":["  0%|          | 0/79175 [00:00<?, ?it/s]\n"]},{"ename":"IndexError","evalue":"index out of range in self","output_type":"error","traceback":["\u001b[1;31m---------------------------------------------------------------------------\u001b[0m","\u001b[1;31mIndexError\u001b[0m                                Traceback (most recent call last)","\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_2180/3704859931.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     12\u001b[0m         \u001b[0mlabels\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mbatch\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'labels'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mto\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     13\u001b[0m         \u001b[1;31m# process\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 14\u001b[1;33m         outputs = model(input_ids, attention_mask=attention_mask,\n\u001b[0m\u001b[0;32m     15\u001b[0m                         labels=labels)\n\u001b[0;32m     16\u001b[0m         \u001b[1;31m# extract loss\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n","\u001b[1;32mc:\\ProgramData\\Anaconda3\\lib\\site-packages\\torch\\nn\\modules\\module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[1;34m(self, *input, **kwargs)\u001b[0m\n\u001b[0;32m   1108\u001b[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n\u001b[0;32m   1109\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[1;32m-> 1110\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1111\u001b[0m         \u001b[1;31m# Do not call functions when jit is used\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1112\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n","\u001b[1;32mc:\\ProgramData\\Anaconda3\\lib\\site-packages\\transformers\\models\\distilbert\\modeling_distilbert.py\u001b[0m in \u001b[0;36mforward\u001b[1;34m(self, input_ids, attention_mask, head_mask, inputs_embeds, labels, output_attentions, output_hidden_states, return_dict)\u001b[0m\n\u001b[0;32m    647\u001b[0m         \u001b[0mreturn_dict\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mreturn_dict\u001b[0m \u001b[1;32mif\u001b[0m \u001b[0mreturn_dict\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m \u001b[1;32melse\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mconfig\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0muse_return_dict\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    648\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 649\u001b[1;33m         dlbrt_output = self.distilbert(\n\u001b[0m\u001b[0;32m    650\u001b[0m             \u001b[0minput_ids\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0minput_ids\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    651\u001b[0m             \u001b[0mattention_mask\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mattention_mask\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n","\u001b[1;32mc:\\ProgramData\\Anaconda3\\lib\\site-packages\\torch\\nn\\modules\\module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[1;34m(self, *input, **kwargs)\u001b[0m\n\u001b[0;32m   1108\u001b[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n\u001b[0;32m   1109\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[1;32m-> 1110\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1111\u001b[0m         \u001b[1;31m# Do not call functions when jit is used\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1112\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n","\u001b[1;32mc:\\ProgramData\\Anaconda3\\lib\\site-packages\\transformers\\models\\distilbert\\modeling_distilbert.py\u001b[0m in \u001b[0;36mforward\u001b[1;34m(self, input_ids, attention_mask, head_mask, inputs_embeds, output_attentions, output_hidden_states, return_dict)\u001b[0m\n\u001b[0;32m    564\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    565\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0minputs_embeds\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 566\u001b[1;33m             \u001b[0minputs_embeds\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0membeddings\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minput_ids\u001b[0m\u001b[1;33m)\u001b[0m  \u001b[1;31m# (bs, seq_length, dim)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    567\u001b[0m         return self.transformer(\n\u001b[0;32m    568\u001b[0m             \u001b[0mx\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0minputs_embeds\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n","\u001b[1;32mc:\\ProgramData\\Anaconda3\\lib\\site-packages\\torch\\nn\\modules\\module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[1;34m(self, *input, **kwargs)\u001b[0m\n\u001b[0;32m   1108\u001b[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n\u001b[0;32m   1109\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[1;32m-> 1110\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1111\u001b[0m         \u001b[1;31m# Do not call functions when jit is used\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1112\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n","\u001b[1;32mc:\\ProgramData\\Anaconda3\\lib\\site-packages\\transformers\\models\\distilbert\\modeling_distilbert.py\u001b[0m in \u001b[0;36mforward\u001b[1;34m(self, input_ids)\u001b[0m\n\u001b[0;32m    127\u001b[0m             \u001b[0mposition_ids\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mposition_ids\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0munsqueeze\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mexpand_as\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minput_ids\u001b[0m\u001b[1;33m)\u001b[0m  \u001b[1;31m# (bs, max_seq_length)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    128\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 129\u001b[1;33m         \u001b[0mword_embeddings\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mword_embeddings\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minput_ids\u001b[0m\u001b[1;33m)\u001b[0m  \u001b[1;31m# (bs, max_seq_length, dim)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    130\u001b[0m         \u001b[0mposition_embeddings\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mposition_embeddings\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mposition_ids\u001b[0m\u001b[1;33m)\u001b[0m  \u001b[1;31m# (bs, max_seq_length, dim)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    131\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n","\u001b[1;32mc:\\ProgramData\\Anaconda3\\lib\\site-packages\\torch\\nn\\modules\\module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[1;34m(self, *input, **kwargs)\u001b[0m\n\u001b[0;32m   1108\u001b[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n\u001b[0;32m   1109\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[1;32m-> 1110\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1111\u001b[0m         \u001b[1;31m# Do not call functions when jit is used\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1112\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n","\u001b[1;32mc:\\ProgramData\\Anaconda3\\lib\\site-packages\\torch\\nn\\modules\\sparse.py\u001b[0m in \u001b[0;36mforward\u001b[1;34m(self, input)\u001b[0m\n\u001b[0;32m    156\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    157\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minput\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mTensor\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m->\u001b[0m \u001b[0mTensor\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 158\u001b[1;33m         return F.embedding(\n\u001b[0m\u001b[0;32m    159\u001b[0m             \u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mweight\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpadding_idx\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmax_norm\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    160\u001b[0m             self.norm_type, self.scale_grad_by_freq, self.sparse)\n","\u001b[1;32mc:\\ProgramData\\Anaconda3\\lib\\site-packages\\torch\\nn\\functional.py\u001b[0m in \u001b[0;36membedding\u001b[1;34m(input, weight, padding_idx, max_norm, norm_type, scale_grad_by_freq, sparse)\u001b[0m\n\u001b[0;32m   2181\u001b[0m         \u001b[1;31m# remove once script supports set_grad_enabled\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2182\u001b[0m         \u001b[0m_no_grad_embedding_renorm_\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mweight\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmax_norm\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnorm_type\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 2183\u001b[1;33m     \u001b[1;32mreturn\u001b[0m \u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0membedding\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mweight\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mpadding_idx\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mscale_grad_by_freq\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msparse\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   2184\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2185\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n","\u001b[1;31mIndexError\u001b[0m: index out of range in self"]}],"source":["epochs = 2\n","\n","for epoch in range(epochs):\n","    # setup loop with TQDM and dataloader\n","    loop = tqdm(loader, leave=True)\n","    for batch in loop:\n","        # initialize calculated gradients (from prev step)\n","        optim.zero_grad()\n","        # pull all tensor batches required for training\n","        input_ids = batch['input_ids'].to(device)\n","        attention_mask = batch['attention_mask'].to(device)\n","        labels = batch['labels'].to(device)\n","        # process\n","        outputs = model(input_ids, attention_mask=attention_mask,\n","                        labels=labels)\n","        # extract loss\n","        loss = outputs.loss\n","        # calculate loss for every parameter that needs grad update\n","        loss.backward()\n","        # update parameters\n","        optim.step()\n","        # print relevant info to progress bar\n","        loop.set_description(f'Epoch {epoch}')\n","        loop.set_postfix(loss=loss.item()) "]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.status.busy":"2022-07-05T16:30:43.138899Z","iopub.status.idle":"2022-07-05T16:30:43.139367Z","shell.execute_reply":"2022-07-05T16:30:43.139153Z","shell.execute_reply.started":"2022-07-05T16:30:43.139131Z"},"trusted":true},"outputs":[],"source":["model.save_pretrained('/kaggle/working/bert-bangla')"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.status.busy":"2022-07-05T16:30:43.140828Z","iopub.status.idle":"2022-07-05T16:30:43.14164Z","shell.execute_reply":"2022-07-05T16:30:43.141401Z","shell.execute_reply.started":"2022-07-05T16:30:43.141378Z"},"trusted":true},"outputs":[],"source":["path = \"./bert-bangla\"\n","\n","model2 = DistilBertForMaskedLM.from_pretrained(path)"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.status.busy":"2022-07-05T16:30:43.142924Z","iopub.status.idle":"2022-07-05T16:30:43.143766Z","shell.execute_reply":"2022-07-05T16:30:43.143533Z","shell.execute_reply.started":"2022-07-05T16:30:43.14351Z"},"trusted":true},"outputs":[],"source":["!pip install git+https://github.com/csebuetnlp/normalizer"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.status.busy":"2022-07-05T16:30:43.145028Z","iopub.status.idle":"2022-07-05T16:30:43.145831Z","shell.execute_reply":"2022-07-05T16:30:43.145598Z","shell.execute_reply.started":"2022-07-05T16:30:43.145574Z"},"trusted":true},"outputs":[],"source":["from normalizer import normalize"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.status.busy":"2022-07-05T16:30:43.147164Z","iopub.status.idle":"2022-07-05T16:30:43.148128Z","shell.execute_reply":"2022-07-05T16:30:43.147874Z","shell.execute_reply.started":"2022-07-05T16:30:43.147849Z"},"trusted":true},"outputs":[],"source":["fill_mask = pipeline(\n","    \"fill-mask\",\n","    model=model2,\n","    tokenizer=tokenizer\n",")\n","\n","print(\n","    fill_mask(\n","        normalize(f\"আমি বাংলায় {fill_mask.tokenizer.mask_token} গাই।\")\n","    )\n",")"]}],"metadata":{"kernelspec":{"display_name":"Python 3.9.7 ('base')","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.9.7"},"vscode":{"interpreter":{"hash":"ad2bdc8ecc057115af97d19610ffacc2b4e99fae6737bb82f5d7fb13d2f2c186"}}},"nbformat":4,"nbformat_minor":4}
